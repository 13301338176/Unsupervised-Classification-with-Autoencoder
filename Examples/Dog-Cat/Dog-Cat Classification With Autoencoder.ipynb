{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Classification With Autoencoder\n",
    "# Dog-Cat Example\n",
    "## Arda Mavi\n",
    "[Arda Mavi - GitHub](https://github.com/ardamavi)<br/>\n",
    "[Dog-Cat GitHub Repo - Arda Mavi](https://github.com/ardamavi/Dog-Cat-Classifier)\n",
    "\n",
    "### Summary:\n",
    "In this project, we use autoencoders for Dog-Cat classification as unsupervised machine learning algorithms with Deep Learning.<br/>\n",
    "#### Give the 'images' , then let the program do the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we look up what is autoencoder:\n",
    "## Dog-Cat Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arda Mavi\n",
    "# Unsupervised Classification With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting Dataset:\n",
    "from get_dataset import get_dataset\n",
    "X_train, X_test, Y_train, Y_test = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# About Dataset:\n",
    "img_size = X_train.shape[1] # 64\n",
    "print('Training shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2] ,'size RGB image.\\n')\n",
    "print('Test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2] ,'size RGB image.\\n')\n",
    "\n",
    "print('Examples:')\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n+1):\n",
    "    # Display some data:\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(X_train[i]*255)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deep Learning Model:\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(64, 64, 3))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checkpoints:\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "checkpoints = []\n",
    "#checkpoints.append(TensorBoard(log_dir='/Checkpoints/logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training Model:\n",
    "epochs = 4\n",
    "batch_size = 1\n",
    "autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n+1):\n",
    "    # Display original:\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(X_test[i]*255)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction:\n",
    "    ax = plt.subplot(2, n, i+n)\n",
    "    plt.imshow(decoded_imgs[i]*255)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we use autoencoder for unsupervised classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Describe the number of classes:\n",
    "num_class = 2\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Dense, Activation, Lambda, Reshape, Flatten\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# Custom classifier function:\n",
    "def classifier_func(x):\n",
    "    return x+x*K.one_hot(K.argmax(x, axis=1), num_classes=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Model:\n",
    "\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "#Encoder:\n",
    "conv_1 = Conv2D(32, (3,3), strides=(1,1))(inputs)\n",
    "act_1 = Activation('relu')(conv_1)\n",
    "maxpool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(act_1)\n",
    "\n",
    "conv_2 = Conv2D(64, (3,3), strides=(1,1), padding='same')(maxpool_1)\n",
    "act_2 = Activation('relu')(conv_2)\n",
    "maxpool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(act_2)\n",
    "    \n",
    "flat_1 = Flatten()(maxpool_2)\n",
    "\n",
    "fc_1 = Dense(256)(flat_1)\n",
    "act_3 = Activation('relu')(fc_1)\n",
    "\n",
    "fc_2 = Dense(128)(act_3)\n",
    "act_4 = Activation('relu')(fc_2)\n",
    "\n",
    "fc_3 = Dense(num_class)(act_4)\n",
    "\n",
    "act_class = Lambda(classifier_func, output_shape=(num_class,))(fc_3)\n",
    "\n",
    "#Decoder:\n",
    "fc_4 = Dense(256)(act_class)\n",
    "act_5 = Activation('relu')(fc_4)\n",
    "\n",
    "fc_5 = Dense(14400)(act_5)\n",
    "act_6 = Activation('relu')(fc_5)\n",
    "reshape_1 = Reshape((15,15,64))(act_6)\n",
    "\n",
    "upsample_1 = UpSampling2D((2, 2))(reshape_1)\n",
    "deconv_1 = Conv2DTranspose(64, (3, 3), strides=(1, 1))(upsample_1)\n",
    "act_7 = Activation('relu')(deconv_1)\n",
    "\n",
    "upsample_2 = UpSampling2D((2, 2))(act_7)\n",
    "deconv_2 = Conv2DTranspose(32, (3, 3), strides=(1, 1))(upsample_2)\n",
    "act_8 = Activation('relu')(deconv_2)\n",
    "\n",
    "conv_3 = Conv2D(3, (3, 3), strides=(1, 1))(act_8)\n",
    "act_9 = Activation('sigmoid')(conv_3)\n",
    "\n",
    "autoencoder = Model(inputs, act_9)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Model:\n",
    "epochs = 4\n",
    "batch_size = 5\n",
    "autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(X_test[i]*255)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i]*255)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split autoencoder:\n",
    "encoder = Model(inputs, act_class)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the code to finding which cluster:\n",
    "`np.argmax(<encoder_output>, axis=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we look up result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.predict(X_train).shape)\n",
    "print(np.argmax(encoder.predict(X_train), axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode = encoder.predict(X_train)\n",
    "\n",
    "class_dict = np.zeros((num_class, num_class))\n",
    "for i, sample in enumerate(Y_train):\n",
    "    class_dict[np.argmax(encode[i], axis=0)][np.argmax(sample)] += 1\n",
    "    \n",
    "print(class_dict)\n",
    "    \n",
    "neuron_class = np.zeros((num_class))\n",
    "for i in range(num_class):\n",
    "    neuron_class[i] = np.argmax(class_dict[i], axis=0)\n",
    "\n",
    "print(neuron_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting class as string:\n",
    "def cat_dog(model_output):\n",
    "    if np.argmax(model_output, axis=0) == 0:\n",
    "        return \"Cat\"\n",
    "    else:\n",
    "        return \"Dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encode = encoder.predict(X_test)\n",
    "\n",
    "predicted = np.argmax(encode, axis=1)\n",
    "for i, sample in enumerate(predicted):\n",
    "    predicted[i] = neuron_class[predicted[i]]\n",
    "\n",
    "comparison = predicted == np.argmax(Y_test, axis=1)\n",
    "loss = 1 - np.sum(comparison.astype(int))/Y_test.shape[0]\n",
    "\n",
    "print('Loss:', loss)\n",
    "print('Examples:')\n",
    "for i in range(10):\n",
    "    plt.imshow(X_test[i]*255)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    neuron = np.argmax(encode[i], axis=0)\n",
    "    print('Class:', cat_dog(Y_test[i]), '- Model\\'s Output Class:', cat_dog(neuron_class[neuron]),'\\n'*2,'-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thats it! Thank you!\n",
    "#### Still in development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
